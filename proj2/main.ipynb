{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee6095fa",
   "metadata": {},
   "source": [
    "# Project 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa2a017",
   "metadata": {},
   "source": [
    "## Load libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4566299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372de540",
   "metadata": {},
   "source": [
    "## Model definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd88c0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        lstm_out = lstm_out[-1] # Only keep the last output in the sequence\n",
    "        out = self.fc(lstm_out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd65e5f",
   "metadata": {},
   "source": [
    "## Train, val, test loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b5de8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm # status bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef32bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, loss_fn, optimizer, epochs=3):\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        epoch_loss = []\n",
    "\n",
    "        for batch_num, (samples, labels) in enumerate(tqdm(data)):\n",
    "\n",
    "            # forward pass\n",
    "            prediction = model(samples.transpose(0,1))\n",
    "            loss = loss_fn(prediction, labels.view(1, -1))\n",
    "\n",
    "            # backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # record loss\n",
    "            epoch_loss.append(loss.log10().item())\n",
    "        \n",
    "        # Print the loss for this epoch\n",
    "        if (epoch+1) % 1 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "        \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12bcfed",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a89f1dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f74e87eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BikeDataset(Dataset):\n",
    "    def __init__(self, csv_file, seq_length, train=True, train_split_ratio=0.7):\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.seq_length = seq_length\n",
    "        self.train = train\n",
    "        \n",
    "        # Perform train/test split\n",
    "        #dataset_size = len(self.data_frame) - self.seq_length\n",
    "        #train_size = int(train_split_ratio * dataset_size)\n",
    "        #test_size = dataset_size - train_size\n",
    "        #print(dataset_size, train_size, test_size)\n",
    "        #self.train_dataset, self.test_dataset = random_split(self.data_frame, [train_size, test_size])\n",
    "        self.train_dataset, self.test_dataset = self.data_frame, self.data_frame\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_dataset) - self.seq_length\n",
    "        else:\n",
    "            return len(self.test_dataset) - self.seq_length\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            dataset = self.train_dataset\n",
    "        else:\n",
    "            dataset = self.test_dataset\n",
    "        beg_idx, end_idx = index, index+self.seq_length\n",
    "        input_features = torch.tensor(dataset.iloc[beg_idx:end_idx,:-1].values,dtype=torch.float32)\n",
    "        target_label = torch.tensor(dataset.iloc[end_idx,-1],dtype=torch.float32)\n",
    "        return input_features, target_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc73b1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CSV file path\n",
    "csv_file = 'data/Bike-Sharing-Dataset/hour.csv'\n",
    "\n",
    "# Create an instance of the custom dataset\n",
    "train_dataset = BikeDataset(csv_file, 12, train=True)\n",
    "test_dataset = BikeDataset(csv_file, 12, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbeb1bd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 1, 11])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# Use PyTorch's DataLoader to create a data loader for batching and shuffling\n",
    "batch_size = 1\n",
    "shuffle = True\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "test_dl = DataLoader(test_dataset, batch_size=1, shuffle=shuffle)\n",
    "\n",
    "# Iterate over the data loader to access batches of data\n",
    "for batch in train_dl:\n",
    "    input_features, target_label = batch\n",
    "    #print('Input Features:', input_features)\n",
    "    #print('Target Label:', target_label)\n",
    "    print(input_features.transpose(0,1).shape)\n",
    "    print(target_label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee1aad9",
   "metadata": {},
   "source": [
    "## Fit models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc7c12e",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82780645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input dimensions, hidden dimensions, and output dimensions\n",
    "input_dim = 11\n",
    "hidden_dim = 50\n",
    "output_dim = 1\n",
    "\n",
    "# Create an instance of the LSTM model\n",
    "model = LSTMModel(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca556788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([12, 1, 11])\n",
      "label shape: torch.Size([1, 1])\n",
      "pred shape: torch.Size([1, 1])\n",
      "torch.Size([12, 1, 11])\n",
      "tensor([[6.0962]], grad_fn=<AddmmBackward0>)\n",
      "tensor([74.])\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "for batch in test_dl:\n",
    "    samples, labels = batch\n",
    "    #print('Samples:', samples)\n",
    "    #print('Label:', labels)\n",
    "    print('input shape:', samples.transpose(0,1).shape)\n",
    "    print('label shape:', labels.view(1, -1).shape)\n",
    "    print('pred shape:', model(samples.transpose(0,1)).shape)\n",
    "    prediction = model(samples.transpose(0,1))\n",
    "    loss = loss_fn(prediction, labels.view(1, -1))\n",
    "    print(samples.transpose(0,1).shape)\n",
    "    print(prediction)\n",
    "    print(labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba73a52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce58ecbacb0e40dc8c619237d5b4a1f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17367 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 24923.5566\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ffa1ed0d634393a2f1b45254cefb9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17367 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Loss: 81.0088\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dfaf7b5097542d5b5d68fb945521cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17367 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Loss: 13734.3086\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b36dcd9ce848fa8ff55f582eaf2231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17367 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Loss: 124.6351\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc62dae42b64b1e9af99274c47093e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17367 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Loss: 1314.3922\n"
     ]
    }
   ],
   "source": [
    "_ = train(model, train_dl, loss_fn, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263bf357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the LSTM model\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    test_input = torch.randn(5, input_dim).unsqueeze(1)\n",
    "    test_output = model(test_input)\n",
    "    print('Input:', test_input.view(-1).numpy())\n",
    "    print('Output:', test_output.view(-1).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23197bc0",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0b935b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72f31e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
