{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee6095fa",
   "metadata": {},
   "source": [
    "# Project 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa2a017",
   "metadata": {},
   "source": [
    "## Load libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4566299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372de540",
   "metadata": {},
   "source": [
    "## Model definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd88c0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        lstm_out = lstm_out[-1] # Only keep the last output in the sequence\n",
    "        out = self.fc(lstm_out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd65e5f",
   "metadata": {},
   "source": [
    "## Train, val, test loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5de8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm # status bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef32bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, loss_fn, optimizer, epochs=3):\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for batch_num, (samples, labels) in enumerate(tqdm(data)):\n",
    "\n",
    "            # forward pass\n",
    "            prediction = model(samples.transpose(0,1))\n",
    "            loss = loss_fn(prediction, labels.view(1, -1))\n",
    "\n",
    "            # backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Print the loss for this epoch\n",
    "        if (epoch+1) % 1 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12bcfed",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89f1dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74e87eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BikeDataset(Dataset):\n",
    "    def __init__(self, csv_file, seq_length, train=True, train_split_ratio=0.7):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.seq_length = seq_length\n",
    "        self.train = train\n",
    "        \n",
    "        # Perform train/test split\n",
    "        dataset_size = len(self.df) - self.seq_length\n",
    "        train_size = int(train_split_ratio * dataset_size)\n",
    "        #self.train_df, self.test_df = self.df, self.df # TODO: not this\n",
    "        self.train_df, self.test_df = self.df[:train_size], self.df[train_size:]\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_df) - self.seq_length\n",
    "        else:\n",
    "            return len(self.test_df) - self.seq_length\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            dataset = self.train_df\n",
    "        else:\n",
    "            dataset = self.test_df\n",
    "        beg_idx, end_idx = index, index+self.seq_length\n",
    "        input_features = torch.tensor(dataset.iloc[beg_idx:end_idx,:-1].values,dtype=torch.float32)\n",
    "        target_label = torch.tensor(dataset.iloc[end_idx,-1],dtype=torch.float32)\n",
    "        return input_features, target_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc73b1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CSV file path\n",
    "csv_file = 'data/Bike-Sharing-Dataset/hour.csv'\n",
    "\n",
    "seq_length = 30\n",
    "\n",
    "# Create an instance of the custom dataset\n",
    "train_dataset = BikeDataset(csv_file, seq_length, train=True)\n",
    "test_dataset = BikeDataset(csv_file, seq_length, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeb1bd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use PyTorch's DataLoader to create a data loader for batching and shuffling\n",
    "batch_size = 1\n",
    "shuffle = True\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "test_dl = DataLoader(test_dataset, batch_size=1, shuffle=shuffle)\n",
    "\n",
    "# Iterate over the data loader to access batches of data\n",
    "for batch in train_dl:\n",
    "    input_features, target_label = batch\n",
    "    #print('Input Features:', input_features)\n",
    "    #print('Target Label:', target_label)\n",
    "    print(input_features.transpose(0,1).shape)\n",
    "    print(target_label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee1aad9",
   "metadata": {},
   "source": [
    "## Fit models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc7c12e",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82780645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input dimensions, hidden dimensions, and output dimensions\n",
    "input_dim = 11\n",
    "hidden_dim = 30\n",
    "output_dim = 1\n",
    "\n",
    "# Create an instance of the LSTM model\n",
    "model = LSTMModel(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca556788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for batch in test_dl:\n",
    "        samples, labels = batch\n",
    "        #print('Samples:', samples)\n",
    "        #print('Label:', labels)\n",
    "        #print('input shape:', samples.transpose(0,1).shape)\n",
    "        #print('label shape:', labels.view(1, -1).shape)\n",
    "        #print('pred shape:', model(samples.transpose(0,1)).shape)\n",
    "        prediction = model(samples.transpose(0,1))\n",
    "        loss = loss_fn(prediction, labels.view(1, -1))\n",
    "        #print(samples.transpose(0,1).shape)\n",
    "        print(prediction)\n",
    "        print(labels.view(1, -1))\n",
    "        print(loss)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba73a52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, train_dl, loss_fn, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23197bc0",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0b935b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72f31e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
