{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29c34e8d",
   "metadata": {},
   "source": [
    "# CS 8770 Project 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b807eb",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef965873",
   "metadata": {},
   "source": [
    "### Load libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116e21ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import Function\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3360a734",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6ad612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9369882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor())\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor())\n",
    "\n",
    "dset = \"MNIST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25d2c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor())\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor())\n",
    "\n",
    "dset = \"FashionMNIST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e48c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_dl = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_dl = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dab3e1",
   "metadata": {},
   "source": [
    "### Model definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c90ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \n",
    "    # H: list of hidden layer dims\n",
    "    # phi: non-linearity to use\n",
    "    # n_classes: num of classes to pred\n",
    "    def __init__(self, H, phi=nn.ReLU(), n_classes=10):\n",
    "        super(MLP, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layers = nn.Sequential()\n",
    "        # create hidden layers based off input list H\n",
    "        H.insert(0,28*28) # input layer\n",
    "        [self.layers.append(nn.Linear(h,l)).append(phi) for h, l in zip(H,H[1:])] # hidden layers\n",
    "        self.layers.append(nn.Linear(H[-1],n_classes)) # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a44b1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single RBF Neuron\n",
    "class RBFNeuron(nn.Module):\n",
    "\n",
    "    # mu: RBF mu vector\n",
    "    # sig: RBF sigma\n",
    "    def __init__(self, mu, sig):\n",
    "        super(RBFNeuron, self).__init__()\n",
    "        self.mu = nn.Parameter(mu)\n",
    "        self.sig = nn.Parameter(sig)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        top = torch.linalg.norm(x-self.mu, dim=1)\n",
    "        return torch.exp(-0.5 * (top / self.sig) ** 2).float().clone().detach()\n",
    "\n",
    "# Layer of RBF Neurons\n",
    "class RBFLayer(nn.Module):\n",
    "\n",
    "    # nin: input dim\n",
    "    # nout: output dim\n",
    "    # mus: list of mean vectors for RBF neurons\n",
    "    # sigs: list of sigmas for RBF neurons\n",
    "    def __init__(self, nin, nout, mus, sigs):\n",
    "        super(RBFLayer, self).__init__()\n",
    "        self.mus = nn.Parameter(mus)\n",
    "        self.sigs = nn.Parameter(sigs)\n",
    "        self.neurons = nn.ModuleList([RBFNeuron(mus[i],sigs[i]) for i in range(nout)])\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return torch.stack([f(x) for f in self.neurons], dim=1)\n",
    "\n",
    "# Full RBF Network\n",
    "class RBFNet(nn.Module):\n",
    "\n",
    "    # mus: list of means to use in basis functions\n",
    "    # sigs: list of sigmas to use in basis functions\n",
    "    # n_classes: num of classes to pred\n",
    "    def __init__(self, mus, sigs, n_classes=10):\n",
    "        super(RBFNet, self).__init__()\n",
    "        self.K = len(mus) # number of RBFs\n",
    "        mus = torch.div(mus, torch.linalg.vector_norm(mus, dim=1).view(-1,1)) # unit norm means\n",
    "        self.mus = nn.Parameter(mus)\n",
    "        self.sigs = nn.Parameter(sigs)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layers = nn.Sequential(\n",
    "            RBFLayer(28*28, self.K, self.mus, self.sigs),\n",
    "            nn.Linear(self.K, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = torch.div(x, torch.linalg.vector_norm(x, dim=1).view(-1,1)) # unit norm x\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcae965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, C, kernel_size=3, pool=2, dropout=0.2, n_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=8,kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(pool),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv2d(in_channels=8, out_channels=64,kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(pool),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(7*7*64, 64),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, n_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.flatten(x)\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98222284",
   "metadata": {},
   "source": [
    "### Train (& validation / test?) loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25604371",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm # status bar\n",
    "\n",
    "def train(model, data, loss_fn, optimizer, epochs=3):\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        epoch_loss = []\n",
    "\n",
    "        for batch, (samples, labels) in enumerate(tqdm(data)):\n",
    "\n",
    "            # forward pass\n",
    "            prediction = model(samples)\n",
    "            loss = loss_fn(prediction, labels)\n",
    "\n",
    "            # backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # record loss\n",
    "            epoch_loss.append(loss.item())\n",
    "\n",
    "        # keep track of loss over our batches\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b26434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data, loss_fn):\n",
    "\n",
    "    for batch, (samples, labels) in enumerate(tqdm(data)):\n",
    "\n",
    "        # forward pass\n",
    "        prediction = model(samples)\n",
    "        loss = loss_fn(prediction, labels)\n",
    "\n",
    "    # test loss\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c16475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_params(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(name, param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b93356",
   "metadata": {},
   "source": [
    "### Fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050a598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61f4b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "learning_rate = 1e-3\n",
    "momentum = 0.3\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05269bc3",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d50aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = MLP([], nn.ReLU(), n_classes=10)\n",
    "\n",
    "optimizer = optim.Adam(mlp_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b583dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(mlp_model, train_dl, loss_fn, optimizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45f7f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(mlp_model, test_dl, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de55444",
   "metadata": {},
   "source": [
    "### RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb7fcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(100, init='k-means++', n_init='auto', random_state=0)\n",
    "kmeans.fit(train_data.data.flatten(1))\n",
    "clusters = kmeans.cluster_centers_.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7166f968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k mean mus\n",
    "# mus = torch.from_numpy(clusters)\n",
    "# sigs = torch.ones(len(mus))*5e-1\n",
    "\n",
    "# train pt mus\n",
    "mus = train_data.data.flatten(1)[:128].float()\n",
    "sigs = torch.ones(len(mus))*5e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b15c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_model = RBFNet(mus, sigs, n_classes=10)\n",
    "\n",
    "optimizer = optim.Adam(rbf_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b9baa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(rbf_model, train_dl, loss_fn, optimizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bb5365",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(rbf_model, test_dl, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622fb8a",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b7b5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = CNN([1,8,64], n_classes=10)\n",
    "\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efac317",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc073c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(cnn_model, train_dl, loss_fn, optimizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9fd60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(cnn_model, test_dl, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ea7212",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3246dac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e7cbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_mnist_classes = np.arange(10)\n",
    "\n",
    "fashion_mnist_classes = {\n",
    "    0: 'T-shirt/top',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle boot'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f509d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = digit_mnist_classes if dset == \"MNIST\" else fashion_mnist_classes\n",
    "\n",
    "# resub because we are loading our MNIST training data set\n",
    "test_dl_2 = DataLoader(dataset=test_data, shuffle=True, batch_size=1)\n",
    "\n",
    "model = rbf_model\n",
    "\n",
    "confusion_mat = torch.zeros((10,10))\n",
    "for sample, label in tqdm(test_dl_2):\n",
    "    \n",
    "    label = int(label.numpy())\n",
    "\n",
    "    prediction = model(sample)\n",
    "    # take the largest output and return integer of which it was (make a classification decision)\n",
    "    prediction = int(torch.argmax(prediction).numpy())\n",
    "    \n",
    "    confusion_mat[label,prediction] += 1\n",
    "    \n",
    "df_cm = pd.DataFrame(np.asarray(confusion_mat),\n",
    "                     index = [C[i] for i in np.arange(10)],\n",
    "                     columns = [C[i] for i in np.arange(10)])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb1c1eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
