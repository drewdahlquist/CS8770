{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "053d7c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import Function\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9daa1893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MulticlassDataset(Dataset):\n",
    "    def __init__(self, num_samples, num_classes, num_features, means, std=1):\n",
    "        super().__init__()\n",
    "        self.num_samples = num_samples\n",
    "        self.num_classes = num_classes\n",
    "        self.num_features = num_features\n",
    "        self.means = means\n",
    "        self.std = std\n",
    "        self.features = torch.zeros((num_samples, num_features))\n",
    "        self.labels = torch.zeros(num_samples, dtype=torch.long)\n",
    "\n",
    "        for i in range(num_samples):\n",
    "            # Randomly choose a class label\n",
    "            class_label = torch.randint(low=0, high=num_classes, size=(1,)).item()\n",
    "            self.labels[i] = class_label\n",
    "\n",
    "            # Generate features based on the mean and standard deviation of the chosen class\n",
    "            self.features[i] = torch.normal(mean=self.means[class_label], std=self.std)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Normalize the feature vector to have unit length\n",
    "        features = self.features[index]\n",
    "        features = features / torch.norm(features)\n",
    "\n",
    "        return features, self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5cd3e580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single RBF Neuron\n",
    "class RBFNeuron(nn.Module):\n",
    "\n",
    "    # mu: RBF mu vector\n",
    "    # sig: RBF sigma\n",
    "    def __init__(self, mu, sig):\n",
    "        super(RBFNeuron, self).__init__()\n",
    "        self.mu = mu\n",
    "        self.sig = sig\n",
    "\n",
    "    def __call__(self, x):\n",
    "        top = torch.linalg.norm(x-self.mu, dim=1)\n",
    "        return torch.exp((-0.5)*(top.pow(2) / self.sig))\n",
    "\n",
    "# Layer of RBF Neurons\n",
    "class RBFLayer(nn.Module):\n",
    "\n",
    "    # nin: input dim\n",
    "    # nout: output dim\n",
    "    # mus: list of mean vectors for RBF neurons\n",
    "    # sigs: list of sigmas for RBF neurons\n",
    "    def __init__(self, nin, nout, mus, sigs):\n",
    "        super(RBFLayer, self).__init__()\n",
    "        self.neurons = nn.ModuleList([RBFNeuron(mus[i],sigs[i]) for i in range(nout)])\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return torch.tensor([f(x).detach().numpy() for f in self.neurons], dtype=torch.float32, requires_grad=False).transpose(0,1)\n",
    "\n",
    "# Full RBF Network\n",
    "class RBFNet(nn.Module):\n",
    "\n",
    "    # mus: list of means to use in basis functions\n",
    "    # sigs: list of sigmas to use in basis functions\n",
    "    # n_classes: num of classes to pred\n",
    "    def __init__(self, mus, sigs, n_classes=10):\n",
    "        super(RBFNet, self).__init__()\n",
    "        self.K = len(mus) # number of RBFs\n",
    "        self.mus = nn.Parameter(mus)#, requires_grad=False)\n",
    "        self.sigs = nn.Parameter(sigs)#, requires_grad=False)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layers = nn.Sequential(\n",
    "            RBFLayer(2, self.K, self.mus, self.sigs),\n",
    "            nn.Linear(self.K, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = (x-x.min())/(x.max()-x.min())\n",
    "        #x = self.flatten(x)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0de0729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm # status bar\n",
    "\n",
    "def train(model, data, loss_fn, optimizer, epochs=5):\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        epoch_loss = []\n",
    "\n",
    "        for batch, (samples, labels) in enumerate(tqdm(data)):\n",
    "\n",
    "            # we need to convert these into tensors\n",
    "            #samples = samples.type('torch.FloatTensor')\n",
    "            #labels = labels.type('torch.LongTensor')\n",
    "\n",
    "            # forward pass\n",
    "            prediction = model(samples)\n",
    "            loss = loss_fn(prediction, labels)\n",
    "\n",
    "            # backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # record loss\n",
    "            epoch_loss.append(loss.item())\n",
    "\n",
    "        # keep track of loss over our batches\n",
    "        #epoch_loss = statistics.mean(epoch_loss)\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cc3cc33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data, loss_fn):\n",
    "\n",
    "    for batch, (samples, labels) in enumerate(tqdm(data)):\n",
    "\n",
    "        # we need to convert these into tensors\n",
    "        #samples = samples.type('torch.FloatTensor')\n",
    "        #labels = labels.type('torch.LongTensor')\n",
    "\n",
    "        # forward pass\n",
    "        prediction = model(samples)\n",
    "        loss = loss_fn(prediction, labels)\n",
    "\n",
    "    # test loss\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3ea18423",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# hyperparams\n",
    "learning_rate = 1e-3\n",
    "momentum = 0.3\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "f002481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000\n",
    "num_classes = 10\n",
    "num_features = 784\n",
    "means = torch.randn(num_classes, num_features)\n",
    "std = 0.5\n",
    "\n",
    "dataset = MulticlassDataset(num_samples, num_classes, num_features, means, std)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5e99e7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mus = means\n",
    "mus = torch.div(means, torch.linalg.vector_norm(means, dim=1).view(-1,1)) # unit norm means\n",
    "sigs = torch.ones(num_classes)*std\n",
    "\n",
    "rbf_model = RBFNet(mus=mus, sigs=sigs, n_classes=num_classes)\n",
    "\n",
    "optimizer = optim.Adam(rbf_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ba60109b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ccda19860f4402f8357592dde198cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8154, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92bd8cde9a7c450e89e1b96a979b3862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6717, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c386f0232e4ae1bb2d7f89cc45763b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5555, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "train(rbf_model, dataloader, loss_fn, optimizer, epochs=epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
